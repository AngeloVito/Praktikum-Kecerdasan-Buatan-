{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4804,"status":"ok","timestamp":1701760959499,"user":{"displayName":"Angelo Vito","userId":"03699334121947608781"},"user_tz":-420},"id":"8UJUGvCClCJR","outputId":"90f8f143-135e-4c0b-dc02-881abda555b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","29515/29515 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26421880/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","5148/5148 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4422102/4422102 [==============================] - 0s 0us/step\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.callbacks import TensorBoard\n","from keras.datasets import fashion_mnist\n","\n","(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n","\n","train_x = train_x.astype('float32') / 255.\n","test_x = test_x.astype('float32') / 255.\n","\n","train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n","test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n","\n","train_y = to_categorical(train_y)\n","test_y = to_categorical(test_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1059,"status":"ok","timestamp":1701760966599,"user":{"displayName":"Angelo Vito","userId":"03699334121947608781"},"user_tz":-420},"id":"VTHQ60lGpT8b","outputId":"0655810e-ae7f-4b57-c56f-72044a19d384"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," zero_padding2d (ZeroPaddin  (None, 32, 32, 1)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d (Conv2D)             (None, 10, 10, 16)        416       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 5, 5, 16)          0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 3, 3, 32)          4640      \n","                                                                 \n"," zero_padding2d_1 (ZeroPadd  (None, 5, 5, 32)          0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          18496     \n","                                                                 \n"," flatten (Flatten)           (None, 576)               0         \n","                                                                 \n"," dense (Dense)               (None, 256)               147712    \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 188362 (735.79 KB)\n","Trainable params: 188362 (735.79 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["# Feature Extraction Layer\n","inputs = Input(shape =(28, 28, 1))\n","conv_layer = ZeroPadding2D(padding =(2, 2))(inputs)\n","conv_layer = Conv2D(16, (5, 5), strides = (3, 3), activation = 'relu')(conv_layer)\n","conv_layer = MaxPooling2D((2, 2))(conv_layer)\n","conv_layer = Conv2D(32, (3, 3), strides = (1, 1), activation = 'relu')(conv_layer)\n","conv_layer = ZeroPadding2D(padding =(1, 1))(conv_layer)\n","conv_layer = Conv2D(64, (3, 3), strides = (1, 1), activation = 'relu')(conv_layer)\n","\n","# Flatten Feature Map to Vector with 576 element.\n","flatten = Flatten()(conv_layer)\n","\n","# Fully Connected Layer\n","fc_layer = Dense(256, activation = 'relu')(flatten)\n","fc_layer = Dense(64, activation = 'relu')(fc_layer)\n","outputs = Dense(10, activation = 'softmax')(fc_layer)\n","\n","model = Model(inputs = inputs, outputs = outputs)\n","\n","# Adam Optimizer and Cross Entropy Loss\n","adam = Adam(lr = 0.0001)\n","model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Print Model Summary\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDCf52wKs3iM"},"outputs":[],"source":["# Feature Extraction Layer\n","inputs = Input(shape =(28, 28, 1))\n","conv_layer = ZeroPadding2D(padding =(2, 2))(inputs)\n","conv_layer = Conv2D(16, (5, 5), strides =(1, 1), activation = 'relu')(conv_layer)\n","conv_layer = MaxPooling2D((2, 2))(conv_layer)\n","conv_layer = Conv2D(32, (3, 3), strides =(1, 1), activation = 'relu')(conv_layer)\n","conv_layer = Conv2D(32, (3, 3), strides =(1, 1), activation = 'relu')(conv_layer)\n","conv_layer = MaxPooling2D((2, 2))(conv_layer)\n","conv_layer = Conv2D(64, (3, 3), strides =(1, 1), activation = 'relu')(conv_layer)\n","\n","# Flatten Feature Map to Vector with 576 element.\n","flatten = Flatten()(conv_layer)\n","\n","# Fully Connected Layer\n","fc_layer = Dense(256, activation = 'relu')(flatten)\n","fc_layer = Dense(64, activation = 'relu')(fc_layer)\n","outputs = Dense(10, activation = 'relu')(fc_layer)\n","\n","model = Model(inputs = inputs, outputs = outputs)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12xuipNavVwa","outputId":"611e5631-22f8-4e2e-da1f-f56407b1804b","executionInfo":{"status":"ok","timestamp":1701765983932,"user_tz":-420,"elapsed":211784,"user":{"displayName":"Angelo Vito","userId":"03699334121947608781"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," zero_padding2d_3 (ZeroPadd  (None, 32, 32, 1)         0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 28, 28, 16)        416       \n","                                                                 \n"," max_pooling2d_3 (MaxPoolin  (None, 14, 14, 16)        0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 12, 12, 32)        4640      \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 10, 10, 32)        9248      \n","                                                                 \n"," max_pooling2d_4 (MaxPoolin  (None, 5, 5, 32)          0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 3, 3, 64)          18496     \n","                                                                 \n"," flatten_2 (Flatten)         (None, 576)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               147712    \n","                                                                 \n"," dense_7 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dense_8 (Dense)             (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 197610 (771.91 KB)\n","Trainable params: 197610 (771.91 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","235/235 [==============================] - 53s 218ms/step - loss: nan - accuracy: 0.1574 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 2/100\n","235/235 [==============================] - 56s 237ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 3/100\n","235/235 [==============================] - 50s 212ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 4/100\n","235/235 [==============================] - 53s 227ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 5/100\n","235/235 [==============================] - 50s 214ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 6/100\n","235/235 [==============================] - 54s 230ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 7/100\n","235/235 [==============================] - 50s 213ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 8/100\n","235/235 [==============================] - 51s 215ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 9/100\n","235/235 [==============================] - 53s 224ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 10/100\n","235/235 [==============================] - 50s 212ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 11/100\n","235/235 [==============================] - 53s 226ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 12/100\n","235/235 [==============================] - 50s 212ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 13/100\n","235/235 [==============================] - 53s 225ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 14/100\n","235/235 [==============================] - 51s 217ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 15/100\n","235/235 [==============================] - 50s 214ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 16/100\n","235/235 [==============================] - 53s 227ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 17/100\n","235/235 [==============================] - 50s 212ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 18/100\n","235/235 [==============================] - 51s 215ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 19/100\n","235/235 [==============================] - 51s 218ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 20/100\n","235/235 [==============================] - 53s 226ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 21/100\n","235/235 [==============================] - 52s 222ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 22/100\n","235/235 [==============================] - 51s 216ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 23/100\n","235/235 [==============================] - 51s 216ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 24/100\n","235/235 [==============================] - 51s 218ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 25/100\n","235/235 [==============================] - 51s 215ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 26/100\n","235/235 [==============================] - 53s 226ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 27/100\n","235/235 [==============================] - 52s 220ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 28/100\n","235/235 [==============================] - 50s 213ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 29/100\n","235/235 [==============================] - 49s 210ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 30/100\n","235/235 [==============================] - 50s 213ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 31/100\n","235/235 [==============================] - 47s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 32/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 33/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 34/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 35/100\n","235/235 [==============================] - 48s 205ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 36/100\n","235/235 [==============================] - 50s 215ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 37/100\n","235/235 [==============================] - 47s 199ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 38/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 39/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 40/100\n","235/235 [==============================] - 47s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 41/100\n","235/235 [==============================] - 50s 212ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 42/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 43/100\n","235/235 [==============================] - 47s 198ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 44/100\n","235/235 [==============================] - 49s 207ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 45/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 46/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 47/100\n","235/235 [==============================] - 50s 211ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 48/100\n","235/235 [==============================] - 51s 216ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 49/100\n","235/235 [==============================] - 48s 205ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 50/100\n","235/235 [==============================] - 48s 205ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 51/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 52/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 53/100\n","235/235 [==============================] - 49s 207ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 54/100\n","235/235 [==============================] - 50s 211ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 55/100\n","235/235 [==============================] - 50s 214ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 56/100\n","235/235 [==============================] - 48s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 57/100\n","235/235 [==============================] - 49s 211ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 58/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 59/100\n","235/235 [==============================] - 48s 203ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 60/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 61/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 62/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 63/100\n","235/235 [==============================] - 50s 211ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 64/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 65/100\n","235/235 [==============================] - 48s 203ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 66/100\n","235/235 [==============================] - 50s 211ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 67/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 68/100\n","235/235 [==============================] - 48s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 69/100\n","235/235 [==============================] - 50s 211ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 70/100\n","235/235 [==============================] - 52s 223ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 71/100\n","235/235 [==============================] - 48s 205ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 72/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 73/100\n","235/235 [==============================] - 49s 210ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 74/100\n","235/235 [==============================] - 51s 216ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 75/100\n","235/235 [==============================] - 47s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 76/100\n","235/235 [==============================] - 49s 207ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 77/100\n","235/235 [==============================] - 51s 216ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 78/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 79/100\n","235/235 [==============================] - 49s 207ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 80/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 81/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 82/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 83/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 84/100\n","235/235 [==============================] - 52s 222ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 85/100\n","235/235 [==============================] - 47s 201ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 86/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 87/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 88/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 89/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 90/100\n","235/235 [==============================] - 48s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 91/100\n","235/235 [==============================] - 49s 209ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 92/100\n","235/235 [==============================] - 49s 206ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 93/100\n","235/235 [==============================] - 51s 217ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 94/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 95/100\n","235/235 [==============================] - 48s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 96/100\n","235/235 [==============================] - 48s 204ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 97/100\n","235/235 [==============================] - 47s 199ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 98/100\n","235/235 [==============================] - 50s 212ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 99/100\n","235/235 [==============================] - 49s 208ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n","Epoch 100/100\n","235/235 [==============================] - 47s 202ms/step - loss: nan - accuracy: 0.1000 - val_loss: nan - val_accuracy: 0.1000\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Activation, Dense, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.callbacks import TensorBoard\n","from keras.datasets import fashion_mnist\n","\n","(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n","\n","train_x = train_x.astype('float32') / 255.\n","test_x = test_x.astype('float32') / 255.\n","\n","train_x = np.reshape(train_x, (len(train_x), 28, 28, 1))\n","test_x = np.reshape(test_x, (len(test_x), 28, 28, 1))\n","\n","train_y = to_categorical(train_y)\n","test_y = to_categorical(test_y)\n","\n","# Feature Extraction Layer\n","inputs = Input(shape =(28, 28, 1))\n","conv_layer = ZeroPadding2D(padding =(2, 2))(inputs)\n","conv_layer = Conv2D(16, (5, 5), strides =(1, 1), activation = 'relu')(conv_layer)\n","conv_layer = MaxPooling2D((2, 2))(conv_layer)\n","conv_layer = Conv2D(32, (3, 3), strides =(1, 1), activation = 'relu')(conv_layer)\n","conv_layer = Conv2D(32, (3, 3), strides =(1, 1), activation = 'relu')(conv_layer)\n","conv_layer = MaxPooling2D((2, 2))(conv_layer)\n","conv_layer = Conv2D(64, (3, 3), strides =(1, 1), activation = 'relu')(conv_layer)\n","\n","# Flatten Feature Map to Vector with 576 element.\n","flatten = Flatten()(conv_layer)\n","\n","# Fully Connected Layer\n","fc_layer = Dense(256, activation = 'relu')(flatten)\n","fc_layer = Dense(64, activation = 'relu')(fc_layer)\n","outputs = Dense(10, activation = 'relu')(fc_layer)\n","\n","model = Model(inputs = inputs, outputs = outputs)\n","\n","# Adam Optimizer and Cross Entropy Loss\n","adam = Adam(lr = 0.0001)\n","model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","# Print Model Summary\n","print(model.summary())\n","\n","# Use TensorBoard\n","callbacks = TensorBoard(log_dir = './Graph')\n","\n","# Train for 100 Epochs and Use TensorBoard Callback\n","model.fit(train_x, train_y, batch_size = 256, epochs = 100, verbose = 1, validation_data =(test_x, test_y), callbacks =[callbacks])\n","\n","# Save Weights\n","model.save_weights('weights.h5')"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6+TIU0w6UpBFfzxIM9VsR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}